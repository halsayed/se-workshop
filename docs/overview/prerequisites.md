


# Workshop Prerequisites

To ensure a successful and productive workshop experience, it is essential that you meet the following prerequisites and complete the pre-work assignments before attending.

## Technical Prerequisites

Participants are expected to have a solid understanding of the following technical concepts:

*   **Kubernetes**: A fundamental understanding of Kubernetes architecture is required, including concepts such as pods, services, deployments, and namespaces. You should be comfortable using the `kubectl` command-line interface (CLI) to interact with a Kubernetes cluster.

*   **Docker**: Docker must be installed and running on your local machine. You should have basic knowledge of running local containers, building Docker images, and using Docker Compose.

*   **REST APIs and JSON**: Familiarity with RESTful APIs and the JSON data format is essential. You should understand how to make API requests and interpret JSON responses.

*   **GenAI Concepts**: A basic awareness of Generative AI (GenAI) concepts is expected. You should be familiar with terms such as Large Language Model (LLM), Retrieval-Augmented Generation (RAG), tokens, and prompt engineering.

## Pre-work Assignments

Please complete the following pre-work assignments before the workshop:

1.  **Watch the NAI Pitch**: Gain a high-level understanding of the Nutanix Enterprise AI value proposition by watching the official NAI pitch video. You can access the video at the following link:
    [NAI Pitch](https://ntnx-intranet--simpplr.vf.force.com/apex/simpplr__app?u=/video/1_niyn7lq3&fileId=1_niyn7lq3&provider=native_video)

2.  **Getting Started with Enterprise AI**: Watch the introductory video on YouTube to familiarize yourself with the basics of Nutanix Enterprise AI.
    [Getting Started with Enterprise AI](https://youtu.be/Cb_xpCLmW8U)

3.  **Review the NAI Demo**: Watch the NAI Demo video to see the platform in action.

4.  **Introduction to LLMs**: Review the "Introduction to LLMs" presentation to build a foundational understanding of Large Language Models.

5.  **Deploy a Basic Chatbot**: Follow the instructions in the provided GitHub repository to deploy a basic chatbot on your local machine. This will give you hands-on experience with the technologies we will be using in the workshop.
    [Nutanix AI Demo GitHub Repository](https://github.com/halsayed/nai-demo)

6.  **Experiment with Prompts**: Spend some time experimenting with different prompts to understand how they influence the output of Large Language Models.

7.  **Create Accounts**:
    *   Create a free account on [Docker Hub](https://hub.docker.com/).
    *   Create a free account on [Hugging Face](https://huggingface.co/).

8.  **Accept Model Usage Policies**: On the Hugging Face website, accept the usage policies for the following models:
    *   [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)
    *   [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)

9.  **Bonus: Skim Additional Workshops**: For extra preparation, you can skim through the following workshop materials:
    *   [NAI on NKP Workshop](https://nai.howntnx.win/iep/)
    *   [Nutanix .Next 2025 AI Labs](https://bootcamps.nutanix.com/next25labs/ai/)
    *   [AI Engineer Roadmap](https://roadmap.sh/ai-engineer)


